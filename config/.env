# Database
DB_TYPE=teradata # Options: postgres, teradata 

# Questions and results paths for batch mode
QUESTIONS_PATH=./test/end2end/questions.txt 
RESULTS_PATH=./test/end2end/

# Prompt template
PROMPT_PATH=./prompt_teradata.txt # Options: prompt_teradata.txt, prompt_postgres.txt

# Postgres connection
DB_HOST=localhost
DB_NAME=raven
DB_USER=postgres
DB_PASSWORD=postgres
DB_PORT=5432

# TD connection
TD_HOST=raven-env-oe7lr1dbadydeuff.env.clearscape.teradata.com
TD_NAME=raven
TD_USER=demo_user
TD_PASSWORD=raven$1234
TD_PORT=1025

# Engine Selection
ENGINE=huggingface # Options: huggingface, ollama

# Model Configuration (for the huggingface engine only)
MODEL_PATH="./models/code-llama-7b-instruct"
MAX_LENGTH=4096 # Maximum context window size for the model
TOKEN_GENERATION_LIMIT=768 # Controls how many new tokens the model will generate during inference
INPUT_CONTEXT_LENGTH=768 # Controls how much of the input prompt is tokenized and fed to the model
RESULT_LIMIT=1
HF_HUB_OFFLINE=1
